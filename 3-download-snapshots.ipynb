{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the snapshots\n",
    "Now that we have the snapshots timestamp, we can download the snapshots from the Wayback Machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "## Read URLs from a JSON file\n",
    "########################\n",
    "\n",
    "import json\n",
    "\n",
    "URL_PATH = \"urls_with_snapshots.json\"\n",
    "\n",
    "# INITIALIZE THE URL LIST\n",
    "url_list = []\n",
    "\n",
    "with open(URL_PATH, \"r\") as f:\n",
    "    url_list = json.load(f)\n",
    "\n",
    "print(f\"Read {len(url_list)} URLs from {URL_PATH}\")\n",
    "print(\"First 5 URLs:\")\n",
    "print(url_list)\n",
    "for url in url_list[:5]:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over the snapshots and download them\n",
    "We iterate over a list of website entries, where each entry contains a URL, an ID, and a collection of snapshots. For each entry, the script:\n",
    "- Creates a unique directory based on the entry's ID within a predefined base directory.\n",
    "  - We cannot use the URL as the directory name because it may contain characters that are not allowed in directory names, such as slashes and colons.\n",
    "- Iterates through each snapshot associated with this entry.\n",
    "- For every snapshot, it:\n",
    "  - Builds a directory for that specific snapshot based on its timestamp.\n",
    "  - Attempts to download the website snapshot from its URL, retrying up to three times in case of failure.\n",
    "  - Saves the downloaded HTML content into a file within the snapshot's directory.\n",
    "  - Pause between each snapshot download to manage request frequency, and extends this pause in case of download errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "DATA_BASE_PATH = \"data\"\n",
    "sleep_time_on_error = 4\n",
    "sleep_time_per_snapshot = 1\n",
    "\n",
    "total_entry_count = len(url_list)\n",
    "\n",
    "for i, entry in enumerate(url_list):\n",
    "    print(f\"Processing entry: {i+1}/{total_entry_count}\")\n",
    "    url = entry[\"url\"]\n",
    "    id = entry[\"id\"]\n",
    "    snapshots = entry[\"snapshots\"]\n",
    "\n",
    "    print(f\"Processing URL: {url}\")\n",
    "\n",
    "    # create a directory for the URL\n",
    "    url_path = os.path.join(DATA_BASE_PATH, id)\n",
    "    os.makedirs(url_path, exist_ok=True)\n",
    "\n",
    "    total_snapshot_count = len(snapshots)\n",
    "    for j, snapshot in enumerate(snapshots):\n",
    "        print(f\"Processing snapshot: {j+1}/{total_snapshot_count}\")\n",
    "        snapshot_url = snapshot[\"url\"]\n",
    "        snapshot_timestamp = snapshot[\"timestamp\"]\n",
    "        # download the website snapshot from the url\n",
    "\n",
    "        # make a directory for the snapshot\n",
    "        snapshot_dir = os.path.join(url_path, str(snapshot_timestamp))\n",
    "        os.makedirs(snapshot_dir, exist_ok=True)\n",
    "\n",
    "        snapshot_path = os.path.join(snapshot_dir, \"snapshot.html\")\n",
    "\n",
    "        if os.path.exists(snapshot_path):\n",
    "            print(f\"Snapshot already exists: {snapshot_path}\")\n",
    "            continue\n",
    "\n",
    "        max_retries = 3\n",
    "\n",
    "        for i in range(max_retries):\n",
    "            try:\n",
    "                # pretend to be a normal browser\n",
    "                response = requests.get(snapshot_url)\n",
    "                print(f\"Downloaded snapshot from {snapshot_url}\")\n",
    "                with open(snapshot_path, \"w\") as f:\n",
    "                    f.write(response.text)\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading snapshot: {e}\")\n",
    "                print(f\"Sleeping for {sleep_time_on_error} seconds\")\n",
    "                time.sleep(sleep_time_on_error)\n",
    "                continue\n",
    "\n",
    "        print(f\"Sleeping for {sleep_time_per_snapshot} seconds\")\n",
    "        time.sleep(sleep_time_per_snapshot)\n",
    "\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congrates! You have downloaded the snapshots.\n",
    "Check out your `data` folder to see the downloaded snapshots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
